#1
import pandas as pd
import matplotlib.pyplot as plt

file = input("Enter CSV file path: ")
df = pd.read_csv(file)

print("\n--- Basic Info ---")
print(df.info())

print("\n--- Statistical Description ---")
print(df.describe())

df.hist(figsize=(10, 6))
plt.show()


#2
import pandas as pd

file = input("Enter CSV file path: ")
df = pd.read_csv(file)

df = df.fillna(df.mean())
df = pd.get_dummies(df)
df = (df - df.min()) / (df.max() - df.min())

print("Preprocessed Data:")
print(df.head())


#3
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt

file = input("Enter CSV file path: ")
df = pd.read_csv(file)

X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = DecisionTreeClassifier()
model.fit(X_train, y_train)

print("Accuracy:", model.score(X_test, y_test))

plt.figure(figsize=(10,6))
plot_tree(model, filled=True, feature_names=X.columns)
plt.show()


#4
import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules

file = input("Enter CSV file path: ")
df = pd.read_csv(file, header=None)
transactions = df.values.tolist()

te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
encoded_df = pd.DataFrame(te_ary, columns=te.columns_)

frequent_items = apriori(encoded_df, min_support=0.3, use_colnames=True)
print("Frequent Itemsets:")
print(frequent_items)

rules = association_rules(frequent_items, metric="lift", min_threshold=1)
print("\nAssociation Rules:")
print(rules)


#5
import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import fpgrowth, association_rules

file = input("Enter CSV file path: ")
df = pd.read_csv(file, header=None)
transactions = df.values.tolist()

te = TransactionEncoder()
te_ary = te.fit(transactions).transform(transactions)
encoded_df = pd.DataFrame(te_ary, columns=te.columns_)

frequent_items = fpgrowth(encoded_df, min_support=0.3, use_colnames=True)
print("Frequent Itemsets:")
print(frequent_items)

rules = association_rules(frequent_items, metric="lift", min_threshold=1)
print("\nAssociation Rules:")
print(rules)


#6
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

file = input("Enter CSV file path: ")
df = pd.read_csv(file)

X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = LinearRegression()
model.fit(X_train, y_train)

print("R^2 Score:", model.score(X_test, y_test))

plt.scatter(X_test.iloc[:, 0], y_test, color='blue')
plt.plot(X_test.iloc[:, 0], model.predict(X_test), color='red')
plt.xlabel("Feature")
plt.ylabel("Target")
plt.show()


#7
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB

file = input("Enter CSV file path: ")
df = pd.read_csv(file)

X = df.iloc[:, :-1]
y = df.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = GaussianNB()
model.fit(X_train, y_train)

print("Accuracy:", model.score(X_test, y_test))
